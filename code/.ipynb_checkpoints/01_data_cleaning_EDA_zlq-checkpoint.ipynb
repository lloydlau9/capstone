{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capstone - Speech Emotion Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install librosa soundfile numpy sklearn pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from matplotlib.pyplot import specgram\n",
    "import pandas as pd\n",
    "import glob \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import IPython.display as ipd  # To play sound in the notebook\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "# ignore warnings \n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile\n",
    "import os, glob, pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve RAVDESS dataset from File System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['03-01-01-01-01-01-01.wav',\n",
       " '03-01-01-01-01-02-01.wav',\n",
       " '03-01-01-01-02-01-01.wav',\n",
       " '03-01-01-01-02-02-01.wav',\n",
       " '03-01-02-01-01-01-01.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# TESS = \"/kaggle/input/toronto-emotional-speech-set-tess/tess toronto emotional speech set data/TESS Toronto emotional speech set data/\"\n",
    "RAV = \"../datasets/RAVDESS/\"\n",
    "#RAV = \"../datasets/RAVDESS/audio_speech_actors_01-24/\"\n",
    "#SAVEE = \"/kaggle/input/surrey-audiovisual-expressed-emotion-savee/ALL/\"\n",
    "#CREMA = \"../datasets/AudioWAV/\"\n",
    "\n",
    "# Run one example \n",
    "dir_list = os.listdir(RAV+\"Actor_01/\")\n",
    "dir_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data statistics by motion and gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ece7a57e5942>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mpart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0memotion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dir_list = os.listdir(RAV)\n",
    "dir_list.sort()\n",
    "\n",
    "emotion = []\n",
    "gender = []\n",
    "path = []\n",
    "#loop to get all actor's sound files path\n",
    "#print(\"actor folder:\"+i)\n",
    "for i in dir_list:\n",
    "    fname = os.listdir(RAV + i)\n",
    "    #to get all actor's relative file path\n",
    "    #print(\"relative path for \"+i+\": \"+RAV+i)\n",
    "    for f in fname:\n",
    "        part = f.split('.')[0].split('-')\n",
    "        emotion.append(int(part[2]))\n",
    "        temp = int(part[6])\n",
    "        if temp%2 == 0:\n",
    "            temp = \"female\"\n",
    "        else:\n",
    "            temp = \"male\"\n",
    "        gender.append(temp)\n",
    "        path.append(RAV + i + '/' + f)\n",
    "\n",
    "        \n",
    "RAV_df = pd.DataFrame(emotion)\n",
    "RAV_df = RAV_df.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'})\n",
    "RAV_df = pd.concat([pd.DataFrame(gender),RAV_df],axis=1)\n",
    "RAV_df.columns = ['gender','emotion']\n",
    "RAV_df['labels'] =RAV_df.gender + '_' + RAV_df.emotion\n",
    "RAV_df['source'] = 'RAVDESS'  \n",
    "RAV_df = pd.concat([RAV_df,pd.DataFrame(path, columns = ['path'])],axis=1)\n",
    "RAV_df = RAV_df.drop(['gender', 'emotion'], axis=1)\n",
    "RAV_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waveform view for Different Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick all the emotions\n",
    "all_emotions=['neutral','calm','happy', 'sad', 'angry', 'fear', 'disgust', 'surprise']\n",
    "data = []\n",
    "sampling_rate = []\n",
    "file_name=[]\n",
    "ax = {}\n",
    "\n",
    "fig, (ax) = plt.subplots(4, 2,figsize=(15,20))\n",
    "\n",
    "fig.suptitle('Waveform for Different Emotions')\n",
    "k=0\n",
    "for i in range (4):\n",
    "    for j in range (2):\n",
    "        #print(RAV + 'Actor_01/03-01-0'+str(k+1)+'-01-01-01.wav')\n",
    "        fr=RAV + 'Actor_01/03-01-0'+str(k+1)+'-01-01-01-01.wav'\n",
    "        da, sr = librosa.load(fr)\n",
    "        data.append(da)\n",
    "        sampling_rate.append(sr)\n",
    "        file_name.append(fr)\n",
    "        ax[i][j].set_title(all_emotions[k])\n",
    "        librosa.display.waveplot(da, sr=sr,ax=ax[i][j])\n",
    "        k=k+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:'neutral', 1:'calm', 2:'happy', 3:'sad', 4:'angry', 5:'fear', 6:'disgust', 7:'surprise'\n",
    "ipd.Audio(file_name[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech Emotion Compared by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick selected the emotions\n",
    "selected_emotions=['calm', 'sad',  'fear', 'surprise']\n",
    "\n",
    "fig, (ax) = plt.subplots(4, 2,figsize=(15,20))\n",
    "file_name_by_gender=[]\n",
    "fig.suptitle('Waveform for Different Emotions')\n",
    "k=2\n",
    "m=0\n",
    "for i in range (4):\n",
    "    for j in range (2):\n",
    "        \n",
    "        if(j==0):\n",
    "            print(RAV + 'Actor_01/03-01-0'+str(k)+'-01-01-01.wav')\n",
    "            fr=RAV + 'Actor_01/03-01-0'+str(k)+'-01-01-01-01.wav'\n",
    "            gender=\"male\"\n",
    "        else :\n",
    "            print(RAV + 'Actor_01/03-01-0'+str(k)+'-01-01-02.wav')\n",
    "            fr=RAV + 'Actor_02/03-01-0'+str(k)+'-01-01-01-02.wav' \n",
    "            gender=\"female\"\n",
    "        da, sr = librosa.load(fr)\n",
    "        file_name_by_gender.append(fr)\n",
    "        ax[i][j].set_title(gender+\" with \"+ selected_emotions[m]+\" emotion\")\n",
    "        librosa.display.waveplot(da, sr=sr,ax=ax[i][j])\n",
    "    k=k+2\n",
    "    m=m+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0:'male with calm', 1:'female with calm', 2:'male with sad', 3:'female with sad', 4:'male with fear', 5:'female with fear', \n",
    "# 6:'male with surprise'7:'female with surprise'\n",
    "ipd.Audio(file_name_by_gender[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrogram View for Different Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = {}\n",
    "fig, (ax1) = plt.subplots(4, 2,figsize=(15,20))\n",
    "fig.suptitle('Spectrogram View for Different Emotions')\n",
    "k=0\n",
    "for i in range (4):\n",
    "    for j in range (2): \n",
    "        Xdb = librosa.amplitude_to_db(abs(librosa.stft(data[k])))\n",
    "        librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz',ax=ax1[i][j])\n",
    "        k=k+1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
